#FORMAT OF ORIGINAL FLOPPY TAIL [KLEIGER, G ET. AL. "RAPID E2-E3 ASSEMBLY AND DISASSEMBLY ENABLE PROCESSICE UBIQUITYLATION OF CULLIN-RING UBIQUITIN LIGASE SUBSTRATES" CELL. 139(5): 957-968 2009]
##CENTROID MODE [NOT DISCLOSED POTENTIALLY RAMA ONLY]
###19 CYCLES: RANDOM: SMALL_180(40%), SHEAR_180(40%), FRAGMENT_3MER(20%)
###20TH CYCLE: MINIMIZATION
####5000 TOTAL CYCLES -> RECOVER LOW
##FULL-ATOM MODE [SCORE12]
###START BY REPACKING ALL IN TAIL/VICINITY OF TAIL FOLLOWED BY MINIMIZATION
###14 CYCLES: RANDOM: SMALL_4(50%), SHEAR_4(50%) FOLLOWED BY SINGLE ROTAMER_TRIALS
###15TH CYCLE:MINIMIZATION
###30TH CYCLE:REPACK THEN MINIMIZATION
####3000 CYCLES -> RECOVER LOW

# The Start-Up
from pyrosetta import *  #Comment
init()
from pyrosetta.rosetta.core.scoring import *
from pyrosetta.rosetta.core.scoring.methods import *
from pyrosetta.rosetta.core.scoring.methods import EnergyMethodOptions
from pyrosetta.rosetta.protocols.grafting import *
from pyrosetta.rosetta.protocols.simple_moves import *
from pyrosetta.rosetta.protocols.moves import *
from pyrosetta.rosetta.core.fragment import *
from pyrosetta.rosetta.protocols.minimization_packing import *
from math import exp, log, pi, sqrt
from random import random as rnd
import sys
import os
import numpy as np
import argparse

# Argument Parsing
parser = argparse.ArgumentParser(description='Program')
parser.add_argument('-in', '--Input_FASTA_File', action='store', type=str, required=False,
	help='Name of the text file containing the FASTA sequence of the protein of interest. Carot should not be in same line as sequence, UniProt format preferred.')
parser.add_argument('-ftnstruct', '--Number_of_FloppyTail_Structures', action='store', type=str, required=False,
	help='Number of structures to sample during FloppyTail portion. Default = 400')
parser.add_argument('-t_frag', '--Three_Mer_Frag_Library', action='store', type=str, required=True,
	help='Name of the file containing the three-mer fragment library generated by disorder corrected method')
parser.add_argument('-cycles', '--FloppyTail_Cycles', action='store', type=str, required=False,
	help='Number of sampling cycles within each stage of FloppyTail, identical to increase_cycles flag in C++ ClassicAbInitio and AbRelax. Default 0')
parser.add_argument('-refinesubset', '--Refine_Subset', action='store', type=int, required=False,
	help='Only subjects the lowest X% of structures to Relax refinement where X is specified as input following flag. Default 0')
parser.add_argument('-relnstruct', '--Number_of_Relax_Structures', action='store', type=str, required=False,
	help='Number of independent full-atom Relax sampling trajectories from a single AbInitio structure. Default 1')
parser.add_argument('-diso', '--Disorder_Probability_Prediction_File', action='store', type=str, required=False,
	help='File containing per residue disorder probability prediction in RaptorX format. Generally acquired from RaptorX prediciton.')
parser.add_argument('-inpdb', '--Input_PDB_File', action='store', type=str, required=False,
	help='Name of the text file containing the PDB structure of the protein of interest. All residues are required, missing residues are not constructed')
parser.add_argument('-code', '--Order_Code', action='store', type=str, required=False,
	help='Single letter code specifying O = ordered, D = disordered, P = partially ordered. If D is supplied, fasta is used, if P is supplied PDB is used')
args = parser.parse_args()

## Imports from Parser and Defaults
if args.Number_of_FloppyTail_Structures:
	ftnstruct = int(args.Number_of_FloppyTail_Structures)
else:
	ftnstruct = 400
if args.FloppyTail_Cycles:
	cycles = int(args.FloppyTail_Cycles)
else:
	cycles = 1
if args.Number_of_Relax_Structures:
	relnstruct = int(args.Number_of_Relax_Structures)
else:
	relnstruct = 0
if args.Refine_Subset:
	refine_number = int((args.Refine_Subset/100)*int(ftnstruct))
else:
	refine_number = 0
	
# Importing sequence from FASTA
if args.Input_FASTA_File:
	fasta_file = open(args.Input_FASTA_File, 'r')
	fasta_lines = fasta_file.readlines()
	fasta_counter = 0
	fasta_sequence = ' '
	for fasta_line in fasta_lines:
		if '>' not in fasta_line:
			if fasta_counter == 0:
				if '\n' in fasta_line:
					fasta_sequence = fasta_line.split('\n')[0]
				else:
					fasta_sequence = fasta_line
				fasta_counter = 1	
			else:
				if '\n' in fasta_line:
					fasta_sequence = fasta_sequence + fasta_line.split('\n')[0]
				else:
					fasta_sequence = fasta_sequence + fasta_line

# Determining the Per Residue Disorder Probability and Number of Segments
if args.Disorder_Probability_Prediction_File:
	disorder_dtypes = [('res_num', np.float_), ('AA', np.unicode_, 2), ('ast', np.unicode_, 1), ('disprob', np.float_)]
	disorder_dat = np.genfromtxt(args.Disorder_Probability_Prediction_File, dtype=disorder_dtypes, delimiter=' ', skip_header=3)
	diso_dat = np.empty((len(disorder_dat),1))
	diso_segments = []
	diso_cutoff = 0.5
	seg_cutoff = 10
	seg_res_counter = 0
	per_residue_disorder = 0
	diso_current = disorder_dat[0][3]
	segment_break_list = []
	segment_switch = False
	for seg_residue in range(len(disorder_dat)):
		if disorder_dat[seg_residue][3] >= diso_cutoff and diso_current >= diso_cutoff:
			seg_res_counter = 0
		elif disorder_dat[seg_residue][3] < diso_cutoff and diso_current < diso_cutoff:
			seg_res_counter = 0
		elif disorder_dat[seg_residue][3] < diso_cutoff and diso_current >= diso_cutoff:
			seg_res_counter = seg_res_counter + 1
		elif disorder_dat[seg_residue][3] >= diso_cutoff and diso_current < diso_cutoff:
			seg_res_counter = seg_res_counter + 1
		if seg_res_counter > 9:
			seg_res_counter = 0
			diso_current = disorder_dat[seg_residue][3]
			if diso_current >= diso_cutoff:
				transition_id = 'order' # meaning all residues prior to end are ordered
			else:
				transition_id = 'disorder' # meaning all residues prior to end are disordered
			segment_break_list.append((seg_residue-9, transition_id))
		per_residue_disorder = per_residue_disorder + (disorder_dat[seg_residue][3]/float(len(disorder_dat)))
	if disorder_dat[len(disorder_dat)-1][3] >= diso_cutoff:
		segment_break_list.append((len(disorder_dat), 'disorder'))
	else:
		segment_break_list.append((len(disorder_dat), 'order'))	

# The Poses
p=Pose()
if args.Input_FASTA_File:
	p = pose_from_sequence(fasta_sequence, "centroid")
if args.Input_PDB_File:
	p = pose_from_pdb(str(args.Input_PDB_File), "centroid")
if args.Order_Code:
	if args.Order_Code == 'D':
		p = pose_from_sequence(fasta_sequence, "centroid")
	if args.Order_Code == 'P':
		p = pose_from_pdb(str(args.Input_PDB_File), "centroid")

starting_p = Pose()
starting_p.assign(p)
pvdw = Pose()
pvdwc = Pose()
pcen = Pose()
cenmap = MoveMap()
cenmap.set_bb(True)
fullmap = MoveMap()
fullmap.set_bb(True)
fullmap.set_chi(True)
relaxmap = MoveMap()
relaxmap.set_bb(True)
relaxmap.set_chi(True)
if args.Disorder_Probability_Prediction_File:
	cenmap.set_bb(False)
	fullmap.set_bb(False)
	fullmap.set_chi(False)
	for res_seg_idx, res_seg_item in enumerate(segment_break_list):
		start_res = 1
		if res_seg_idx > 0:
			start_res = segment_break_list[res_seg_idx-1][0] + 1
		end_res = res_seg_item[0] + 1
		if res_seg_item[1] == 'disorder':
			for res_idx in range(start_res,end_res+1):
				cenmap.set_bb(res_idx, True)
				fullmap.set_bb(res_idx, True)
				fullmap.set_chi(res_idx, True)
		else:
			continue			

# The Score Functions
## VDW Repulsive Score Function
sf_stage_0 = create_score_function('score0')

## Centroid Score Functions
sf_stage_1 = create_score_function('cen_std')
sf_stage_1.set_weight(rama, 1.0)
sf_stage_1.set_weight(cenpack, 1.0)
sf_stage_1.set_weight(hbond_lr_bb, 1.0)
sf_stage_1.set_weight(hbond_sr_bb, 1.0)

## Full Atom Score Functions
sf_stage_2 = create_score_function('ref2015')
sf_relax = create_score_function('ref2015_cart')

## Radius of Gyration Reference Score Function
sfrg = ScoreFunction()
sfrg.set_weight(rg, 1.0)

# The Movers
## Fragment Movers
# Importing the Fragment Files
fragset3 = ConstantLengthFragSet(3)
fragset3.read_fragment_file(args.Three_Mer_Frag_Library)

# Constructing the Fragment Mover
fragmover3 = ClassicFragmentMover(fragset3, cenmap)

## Minimization Movers
vdwmin = MinMover()
vdwmin.movemap(cenmap)
vdwmin.score_function(sf_stage_0)
vdwmin.min_type('linmin')

cenmin = MinMover()
cenmin.movemap(cenmap)
cenmin.score_function(sf_stage_1)
cenmin.min_type('linmin')

fullmin = MinMover()
fullmin.movemap(fullmap)
fullmin.score_function(sf_stage_2)
fullmin.min_type('linmin')

## Phi-Psi Movers
vdw_small_mover = SmallMover(cenmap, 1.0, 1)
vdw_shear_mover = ShearMover(cenmap, 1.0, 1)
vdw_small_mover.angle_max(180)
vdw_small_mover.angle_max("H", 180)
vdw_small_mover.angle_max("E", 180)
vdw_small_mover.angle_max("L", 180)
vdw_shear_mover.angle_max(180)
vdw_shear_mover.angle_max("H", 180)
vdw_shear_mover.angle_max("E", 180)
vdw_shear_mover.angle_max("L", 180)
random_stage_0 = RandomMover()
random_stage_0.add_mover(vdw_small_mover)
random_stage_0.add_mover(vdw_shear_mover)
vdwrepeat = RepeatMover(random_stage_0, 7)

cen_small_mover = SmallMover(cenmap, 0.8, 1)
cen_shear_mover = ShearMover(cenmap, 0.8, 1)
cen_small_mover.angle_max(180)
cen_small_mover.angle_max("H", 180)
cen_small_mover.angle_max("E", 180)
cen_small_mover.angle_max("L", 180)
cen_shear_mover.angle_max(180)
cen_shear_mover.angle_max("H", 180)
cen_shear_mover.angle_max("E", 180)
cen_shear_mover.angle_max("L", 180)

random_stage_1 = RandomMover()
random_stage_1.add_mover(cen_small_mover)
random_stage_1.add_mover(cen_small_mover)
random_stage_1.add_mover(cen_small_mover)
random_stage_1.add_mover(cen_small_mover)
random_stage_1.add_mover(cen_shear_mover)
random_stage_1.add_mover(cen_shear_mover)
random_stage_1.add_mover(cen_shear_mover)
random_stage_1.add_mover(cen_shear_mover)
random_stage_1.add_mover(fragmover3)
random_stage_1.add_mover(fragmover3)

full_small_mover = SmallMover(fullmap, 0.8, 1)
full_shear_mover = ShearMover(fullmap, 0.8, 1)
full_small_mover.angle_max(4)
full_small_mover.angle_max("H", 4)
full_small_mover.angle_max("E", 4)
full_small_mover.angle_max("L", 4)
full_shear_mover.angle_max(4)
full_shear_mover.angle_max("H", 4)
full_shear_mover.angle_max("E", 4)
full_shear_mover.angle_max("L", 4)
full_random = RandomMover()
full_random.add_mover(full_small_mover)
full_random.add_mover(full_shear_mover) 

## Packing/Rotamer Movers
## Converting the Pose
switch = SwitchResidueTypeSetMover('fa_standard')
switch_cen = SwitchResidueTypeSetMover('centroid')

### The Task Operations
switch.apply(p)
fulltask = standard_packer_task(p)
fulltask.restrict_to_repacking()
switch_cen.apply(p)

### The Rotamer Movers
fullpack = PackRotamersMover(sf_stage_2, fulltask)
fullrottrial = RotamerTrialsMover(sf_stage_2, fulltask)

## Sequence Movers
random_stage_0 = SequenceMover()
random_stage_0.add_mover(vdwrepeat)
random_stage_0.add_mover(vdwmin)

random_stage_2 = SequenceMover()
random_stage_2.add_mover(full_random)
random_stage_2.add_mover(fullrottrial)

## Setting up the Monte-Carlo
mc_stage_0 = MonteCarlo(p, sf_stage_0, 10.0)
mc_stage_1 = MonteCarlo(p, sf_stage_1, 1.0)
switch.apply(p)
mc_stage_2 = MonteCarlo(p, sf_stage_2, 1.0)
switch_cen.apply(p)

## Setting up Trial Movers
trial_stage_0 = TrialMover(random_stage_0, mc_stage_0)
trial_stage_1a = TrialMover(random_stage_1, mc_stage_1)
trial_stage_1b = TrialMover(cenmin, mc_stage_1)
trial_stage_2a = TrialMover(random_stage_2, mc_stage_2)
trial_stage_2b = TrialMover(fullmin, mc_stage_2)
trial_stage_2c = TrialMover(fullpack, mc_stage_2)

## Setting up Repeat Movers
stage_0 = RepeatMover(trial_stage_0, 1000)
stage_1a = RepeatMover(trial_stage_1a, 19)
stage_1b = RepeatMover(trial_stage_1b, 1)
stage_2a = RepeatMover(trial_stage_2a, 14)
stage_2b = RepeatMover(trial_stage_2b, 1)
stage_2c = RepeatMover(trial_stage_2c, 1)

# Setting up FastRelax
relax = rosetta.protocols.relax.FastRelax()
relax.min_type('lbfgs_armijo_nonmonotone')
relax.dualspace(True)
relax.set_scorefxn(sf_relax)
relax.max_iter(200)
relax.set_movemap(relaxmap)

# The Simulation and Output
for i in range(ftnstruct):
	p.assign(starting_p)
	mc_stage_0.reset(p)
	mc_stage_1.reset(p)
	stage_0.apply(p)
	for j in range(cycles*250):
		stage_1a.apply(p)
		stage_1b.apply(p)
		if j % 50 == 0:
			sf_stage_1.show(p)
	mc_stage_1.recover_low(p)
	switch.apply(p)
	mc_stage_2.reset(p)
	for k in range(cycles*100):
		stage_2a.apply(p)
		stage_2b.apply(p)
		stage_2a.apply(p)
		stage_2c.apply(p)
		stage_2b.apply(p)
		if k % 25 == 0:
			sf_stage_2.show(p)
	mc_stage_2.recover_low(p)	
	outf = open("FloppyTail.sc", 'a')
	pdb_out = "FloppyTail_out_%i.pdb" %i
	outf.write("%s\t%.3f\t%.3f\n" % (pdb_out, sf_stage_2(p), sfrg(p)))
	p.dump_pdb(pdb_out)
	outf.close()
	
## Deciding who to minimize
dtype_list = [('out_name','S50'),('full_sc',float),('out_rg',float)]
ft_out_data = np.genfromtxt('FloppyTail.sc', dtype=dtype_list)
ft_out_sort = np.sort(ft_out_data, order='full_sc')
for ft_out_struct_idx in range(refine_number):
	ft_out_struct_item = ft_out_data[ft_out_struct_idx]['out_name']
	relax_p_in = pose_from_pdb(str(ft_out_struct_item))
	relax_p = Pose()
	print('Relaxing Output ' + str(ft_out_struct_idx+1) + ' of ' + str(refine_number))
	for relnstruct_idx in range(relnstruct):
		relax_p.assign(relax_p_in)
		relax.apply(relax_p)
		sfrelax.show(relax_p)
		outf = open("Relaxed_FloppyTail.sc", 'a')
		pdb_out = "Relaxed_" + str(ft_out_struct_idx) + "_" + str(relnstruct_idx) + ".pdb" 
		outf.write("%s\t%s\t%.4f\t%.4f\n" % (pdb_out, str(ft_out_struct_item), sfrelax(relax_p), sfrg(relax_p)))
		relax_p.dump_pdb(pdb_out)
		outf.close()	