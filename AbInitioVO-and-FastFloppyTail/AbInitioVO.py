# The Start-Up
from pyrosetta import *  ## for newer versions make all start-up commands with pyrosetta
init()
from math import exp, log, pi, sqrt
from random import random as rnd
from random import randint
import sys
import os
import numpy as np
from pyrosetta.rosetta.core.scoring import *
from pyrosetta.rosetta.core.scoring.methods import *
from pyrosetta.rosetta.core.scoring.methods import EnergyMethodOptions
from pyrosetta.rosetta.protocols.grafting import *
from pyrosetta.rosetta.protocols.simple_moves import *
from pyrosetta.rosetta.protocols.moves import *
from pyrosetta.rosetta.core.fragment import *
from pyrosetta.rosetta.protocols.minimization_packing import *
import scipy.optimize as op
from scipy.interpolate import interp1d
import argparse

# Argument Parsing
parser = argparse.ArgumentParser(description='Program')
parser.add_argument('-in', '--Input_FASTA_File', action='store', type=str, required=True,
	help='Name of the text file containing the FASTA sequence of the protein of interest. Carot should not be in same line as sequence, UniProt format preferred.')
parser.add_argument('-abnstruct', '--Number_of_AbInitio_Structures', action='store', type=str, required=False,
	help='Number of structures to sample during Centroid AbInitio portion. Default = 1000')
parser.add_argument('-diso', '--Input_DisoPred_File', action='store', type=str, required=True,
	help='Name of the file containing the per residue disordered probability prediction generated by RaptorX')
parser.add_argument('-t_frag', '--Three_Mer_Frag_Library', action='store', type=str, required=True,
	help='Name of the file containing the three-mer fragment library generated by disorder corrected method')
parser.add_argument('-n_frag', '--Nine_Mer_Frag_Library', action='store', type=str, required=True,
	help='Name of the file containing the nine-mer fragment library generated by disorder corrected method')
parser.add_argument('-rsd_wt_helix', '--Residue_Weight_Helix', action='store', type=float, required=False,
	help='Reweights the env, pair and cbeta scores for helical residues by specificied factor. Default: 0.5')
parser.add_argument('-rsd_wt_loop', '--Residue_Weight_Loop', action='store', type=float, required=False,
	help='Reweights the env, pair and cbeta scores for loop residues by specificied factor. Default: 0.5')
parser.add_argument('-rsd_wt_sheet', '--Residue_Weight_Sheet', action='store', type=float, required=False,
	help='Reweights the env, pair and cbeta scores for sheet residues by specificied factor. Default: 1.0')
parser.add_argument('-rg_weight', '--Rg_Weight', action='store', type=float, required=False,
	help='Reweights the weight of rg in each step by specificied factor. Default: 0.5')
parser.add_argument('-cycles', '--AbInitio_Cycles', action='store', type=str, required=False,
	help='Number of sampling cycles within each stage of AbInitio, identical to increase_cycles flag in C++ ClassicAbInitio and AbRelax. Default 10')
parser.add_argument('-abinitiovo', '--AbInitioVO', action='store_true', required=False,
	help='Boolean for running protocol with AbInitioVO score function, runs with flag')
parser.add_argument('-refinesubset', '--Refine_Subset', action='store', type=int, required=False,
	help='Only subjects the lowest X% of structures to Relax refinement where X is specified as input following flag. Default 100')
parser.add_argument('-relnstruct', '--Number_of_Relax_Structures', action='store', type=str, required=False,
	help='Number of independent full-atom Relax sampling trajectories from a single AbInitio structure. Default 50')
args = parser.parse_args()

## Imports from Parser and Defaults
if args.Number_of_AbInitio_Structures:
	abnstruct = int(args.Number_of_AbInitio_Structures)
else:
	abnstruct = 20
if args.AbInitio_Cycles:
	cycles = int(args.AbInitio_Cycles)
else:
	cycles = 10
if args.Number_of_Relax_Structures:
	relnstruct = int(args.Number_of_Relax_Structures)
else:
	relnstruct = 50
if args.Refine_Subset:
	refine_number = int((args.Refine_Subset/100)*int(abnstruct))
else:
	refine_number = int(abnstruct)

# Importing sequence from FASTA
fasta_file = open(args.Input_FASTA_File, 'r')
fasta_lines = fasta_file.readlines()
fasta_counter = 0
fasta_sequence = ' '
for fasta_line in fasta_lines:
	if '>' not in fasta_line:
		if fasta_counter == 0:
			if '\n' in fasta_line:
				fasta_sequence = fasta_line.split('\n')[0]
			else:
				fasta_sequence = fasta_line
			fasta_counter = 1
		else:
			if '\n' in fasta_line:
				fasta_sequence = fasta_sequence + fasta_line.split('\n')[0]
			else:
				fasta_sequence = fasta_sequence + fasta_line

# The Poses
#p=Pose()
#make_pose_from_sequence(p, fasta_sequence, "centroid")
p = pose_from_sequence(fasta_sequence, "centroid")
starting_p = Pose()
starting_p.assign(p)
fa_p = Pose()
fa_p.assign(p)
pvdw = Pose()
pvdwc = Pose()
pcen = Pose()
maplow = MoveMap()
maplow.set_bb(True)
maplow.set_chi(True)

# Score Functions
## Preparing the Rg Score Term
#### Determining the Per Residue Disorder Probability and Number of Segments
disorder_dtypes = [('res_num', np.float_), ('AA', np.unicode_, 2), ('ast', np.unicode_, 1), ('disprob', np.float_)]
disorder_dat = np.genfromtxt(args.Input_DisoPred_File, dtype=disorder_dtypes, delimiter=' ', skip_header=3)
diso_dat = np.empty((len(disorder_dat),1))
diso_segments = []
diso_cutoff = 0.5
seg_cutoff = 10
seg_res_counter = 0
per_residue_disorder_sum = 0
per_residue_disorder = 0
first_ten_diso_sum = 0
for seg_residue_ten in range(10):
	first_ten_diso_sum += disorder_dat[seg_residue_ten][3]
diso_current = first_ten_diso_sum/10
segment_break_list = []
segment_switch = False
for seg_residue in range(len(disorder_dat)):
	if disorder_dat[seg_residue][3] >= diso_cutoff and diso_current >= diso_cutoff:
		seg_res_counter = 0
	elif disorder_dat[seg_residue][3] < diso_cutoff and diso_current < diso_cutoff:
		seg_res_counter = 0
	elif disorder_dat[seg_residue][3] < diso_cutoff and diso_current >= diso_cutoff:
		seg_res_counter = seg_res_counter + 1
	elif disorder_dat[seg_residue][3] >= diso_cutoff and diso_current < diso_cutoff:
		seg_res_counter = seg_res_counter + 1
	if seg_res_counter > 9:
		segment_switch = True
		seg_res_counter = 0
		diso_current = disorder_dat[seg_residue][3]
		if diso_current >= diso_cutoff:
			transition_id = 'order' # meaning all residues prior to end are ordered
		else:
			transition_id = 'disorder' # meaning all residues prior to end are disordered
		segment_break_list.append((seg_residue-9, transition_id))
	per_residue_disorder_sum += disorder_dat[seg_residue][3]
	per_residue_disorder = per_residue_disorder_sum/(float(seg_residue)+1)
if segment_switch == True:
	if segment_break_list[len(segment_break_list)-1][1] == 'order':
		segment_break_list.append((len(disorder_dat), 'disorder'))
	else:
		segment_break_list.append((len(disorder_dat), 'order'))
else:
	if per_residue_disorder >= diso_cutoff:
		segment_break_list.append((len(disorder_dat), 'disorder'))
	else:
		segment_break_list.append((len(disorder_dat), 'order'))
#### Computing the Mean Hydrophobicity per Residue
scaling_info_holder = np.zeros([len(segment_break_list),5]) # Need spots for segH,segQ,frac_pos,frac_neg,seq_len -> scalvQ,scalvH,scalv,rad_gyr,seq_len => scalvQ -> sf_rg_term_potential

##### Kyte, J. Doolitte, R.F. J. Mol. Biol. (1982) 157, 105-132
##### Normalization proposed in Uversky, V.N. et. al. Proteins: Struc. Func. Gen. (2000), 41, 415-427
aa_hydro_idx = {'I':4.5, 'V':4.2, 'L':3.8, 'F':2.8, 'C':2.5, 'M':1.9, 'A':1.8, 'G':-0.4, 'T':-0.7, 'W':-0.9, 'S':-0.8, 'Y':-1.3, 'P':-1.6, 'H':-3.2, 'E':-3.5, 'Q':-3.5, 'D':-3.5, 'N':-3.5, 'K':-3.9, 'R':-4.5}
for diso_segment_idx, diso_segment_item in enumerate(segment_break_list):
	start_res = 1
	if diso_segment_idx > 0:
		start_res = segment_break_list[diso_segment_idx-1][0] + 1
	end_res = diso_segment_item[0] + 1
	seq_len = end_res-start_res
	pro_len = p.total_residue()
	scaling_info_holder[diso_segment_idx][4] = seq_len
	sequence_avg_H = 0
	for res_idx in range(start_res-1, end_res-1, 1):
		window_start = 0
		window_end = 0
		window_H_avg = 0
		if res_idx < 5:
			window_start = 0
			window_end = res_idx + 1
		elif pro_len - res_idx < 5:
			window_start = res_idx
			window_end = pro_len
		else:
			window_start = res_idx - 2
			window_end = res_idx + 3
		window = p.sequence()[window_start:window_end]
		for window_res_idx, window_res_item in enumerate(window):
			window_H_avg = window_H_avg + ((aa_hydro_idx[str(window_res_item)]+4.5)/9.0)
		window_H_avg = window_H_avg/(len(window))
		sequence_avg_H = sequence_avg_H + window_H_avg/scaling_info_holder[diso_segment_idx][4]
		scaling_info_holder[diso_segment_idx][0] = sequence_avg_H

#### Computing the Mean Net Charge per Residue
for diso_segment_idx, diso_segment_item in enumerate(segment_break_list):
	start_res = 1
	if diso_segment_idx > 0:
		start_res = segment_break_list[diso_segment_idx-1][0] + 1
	end_res = diso_segment_item[0] + 1
	seq_len = end_res-start_res
	scaling_info_holder[diso_segment_idx][4] = seq_len
	sequence_Q = 0
	frac_pos = 0 # fraction of positively charged residues Arg Lys
	frac_neg = 0 # fraction of negatively charged residues Asp Glu
	for res_idx in range(start_res-1, end_res-1, 1):
		res_id = p.sequence()[res_idx]
		if res_id == 'E' or res_id == 'D':
			frac_neg = frac_neg + 1/seq_len
			sequence_Q = sequence_Q - 1/seq_len
		elif res_id == 'K' or res_id == 'R':
			frac_pos = frac_pos + 1/seq_len
			sequence_Q = sequence_Q + 1/seq_len
		else:
			continue
	sequence_Q = np.sqrt(sequence_Q**2)
	scaling_info_holder[diso_segment_idx][1] = sequence_Q
	scaling_info_holder[diso_segment_idx][2] = frac_pos
	scaling_info_holder[diso_segment_idx][3] = frac_neg

#### Calculations from Hofmann, H. et al. PNAS (2012) 109, 40, 16155-16160
##### Compute charge and hydrophobicity scaling options
###### Constants
scalv = 0
con_a = 0.394
con_z = 0.09
con_x0 = 0.114
con_c = 1.72
con_d = 0.9

###### Calculations
###### Folded vs Unfolded
###### From Uversky, if sequence_Q < 2.785*sequence_avg_H - 1.151 -> Folded, but fails for synuclein
for QH_set_idx in range(len(scaling_info_holder)):
	if 'order' in segment_break_list[QH_set_idx]:
		scaling_info_holder[QH_set_idx][0] = 0.33
		scaling_info_holder[QH_set_idx][1] = 0.33
	else:
		scalv_Q = (1.0/3.0) + con_a*((1+np.exp(con_x0-scaling_info_holder[QH_set_idx][1]/con_z))**(-1))
		scaling_info_holder[QH_set_idx][1] = scalv_Q
		scalv_H = (1.0/3.0) + con_a*((1+np.exp((con_x0+con_c*scaling_info_holder[QH_set_idx][0]-con_d)/con_z))**(-1))
		scaling_info_holder[QH_set_idx][0] = scalv_H

###### Determining the appropriate scaling value
####### Constants
elemchar = 1.602*10**(-19)
ss_eo = 8.854*10**(-12)
ss_er = 78.7 #permittivity of water at 298 K
ss_kb = 1.38*10**(-23) # boltzmann constant
ss_T = 298 # in Kelvin
ss_I = 0.15 # in Molar
ss_kappa = 1/(0.304*np.sqrt(ss_I)) # in nanometers
ss_lB = (elemchar**2)/(4*np.pi*ss_eo*ss_er*ss_kb*ss_T)

####### Calculation
for QH_set_idx in range(len(scaling_info_holder)):
	scalvstar = ((4*np.pi*ss_lB*((scaling_info_holder[QH_set_idx][2]-scaling_info_holder[QH_set_idx][3])**2))/(ss_kappa**2)) - ((np.pi*ss_lB*((scaling_info_holder[QH_set_idx][2]+scaling_info_holder[QH_set_idx][3])**2))/(ss_kappa))
	if scaling_info_holder[QH_set_idx][2] == 0:
		if scaling_info_holder[QH_set_idx][3] == 0:
			scalv = scaling_info_holder[QH_set_idx][0]
		else:
			scalv = scaling_info_holder[QH_set_idx][1]
	elif scaling_info_holder[QH_set_idx][3] == 0:
		if scaling_info_holder[QH_set_idx][2] == 0:
			scalv = scaling_info_holder[QH_set_idx][0]
		else:
			scalv = scaling_info_holder[QH_set_idx][1]
	elif scalvstar < 0:
		scalv = scaling_info_holder[QH_set_idx][1]
	else:
		scalv = scaling_info_holder[QH_set_idx][0]
	scaling_info_holder[QH_set_idx][2] = scalv

##### Computing the Expected Radius of Gyration
rg_b = 0.38 # in nanometers
rg_lp = 0.53 # in nanometers
for QH_set_idx in range(len(scaling_info_holder)):
	rad_gyr = (np.sqrt((2*rg_lp*rg_b)/((2*scaling_info_holder[QH_set_idx][2]+1)*(2*scaling_info_holder[QH_set_idx][2]+2)))*(scaling_info_holder[QH_set_idx][4]**scaling_info_holder[QH_set_idx][2]))*10 # in Angstroms
	scaling_info_holder[QH_set_idx][3] = rad_gyr

## Making the Actual Potential Energy Function
## Constants for Probability
gamma = 1.1615

## Concocting the Potential
def pr_saw(var_a, input_vars):
	r, rg, g, delta = input_vars
	return (var_a[0]*4*np.pi/rg)*((r/rg)**(2+g))*np.exp(-var_a[1]*((r/rg)**delta))

def solve_pr_saw(var_a, *input_vars):
	r, rg, g, delta = input_vars
	return (np.sum((var_a[0]*4*np.pi/rg)*((r/rg)**(2+g))*np.exp(-var_a[1]*((r/rg)**delta)))-1, np.sum((var_a[0]*4*np.pi/rg)*((r/rg)**(2+g))*np.exp(-var_a[1]*((r/rg)**delta))*(r**2))-rg**2)

rg_sf_term_potential_list = []
for QH_set_idx in range(len(scaling_info_holder)):
	var_g = (gamma-1)/scaling_info_holder[QH_set_idx][2]
	var_delta = 1/(1-scaling_info_holder[QH_set_idx][2])
	r_set=np.arange(0.0,7*scaling_info_holder[QH_set_idx][3],0.01)
	saw_inputs = (r_set, scaling_info_holder[QH_set_idx][3], var_g, var_delta)
	a0 = [1.0, 1.0]
	a1 = op.fsolve(solve_pr_saw,a0,args=saw_inputs)
	rg_sf_term_potential = interp1d(r_set, (1-(pr_saw(a1, saw_inputs)/np.max(pr_saw(a1, saw_inputs)))))
	rg_sf_term_potential_list.append(rg_sf_term_potential)

## Making the Actual Score Term
from pyrosetta.rosetta.core.scoring.methods import ContextIndependentOneBodyEnergy ## newer versions make this pyrosetta.rosetta
@pyrosetta.EnergyMethod() ## for newer versions make pyrosetta.EnergyMethod()
class SeqCorrRgMethod(WholeStructureEnergy):
	"""A scoring method that using a predicted radius of gyration from the
	primary sequence to construct a polymer-scaled potential

	"""
	def __init__(self):
		"""Construct LengthScoreMethod."""
		WholeStructureEnergy.__init__(self, self.creator())

	def finalize_total_energy(self, pose, sfxn, emap):
		"""Calculate energy of res of pose and emap"""
		pose = pose ## for newer versions remove line
		e_val = 0
		for segment_idx in range(len(segment_break_list)):
			r_xyz = np.zeros([int(scaling_info_holder[segment_idx][4]), 3])
			rg_sq = np.zeros([int(scaling_info_holder[segment_idx][4]), 1])
			start_res = 1
			if segment_idx > 0:
				start_res = segment_break_list[segment_idx-1][0] + 1
			end_res = segment_break_list[segment_idx][0] + 1
			for res_num in range(start_res, end_res, 1):
				for res_xyz in range(len(r_xyz[0])):
					r_xyz[res_num-start_res][res_xyz] = pose.residue(res_num).nbr_atom_xyz()[res_xyz]
			r_cen_mass = np.average(r_xyz, axis=0)
			for res_num in range(len(r_xyz)):
				rg_sq[res_num] = (np.linalg.norm(r_xyz[res_num] - r_cen_mass))**2
			rg_val = np.sqrt(np.average(rg_sq))
			if rg_val < 7*scaling_info_holder[segment_idx][3]:
				rg_sf_term_potential = rg_sf_term_potential_list[segment_idx]
				e_val = e_val + float(rg_sf_term_potential(rg_val))
			else:
				rg_sf_term_potential = rg_sf_term_potential_list[segment_idx]
				e_val = e_val + float(rg_sf_term_potential(6.9*scaling_info_holder[segment_idx][3]))	
		emap.set(self.scoreType, e_val) ## for newer versions remove .get()

new_rg_score = SeqCorrRgMethod.scoreType

## DSSP-based Reweighting Score Terms
dssp = rosetta.protocols.moves.DsspMover()
dssp_E_weight = 0.0
dssp_L_weight = 0.0
dssp_H_weight = 0.0

if args.Residue_Weight_Sheet:
	dssp_E_weight = 1.0 - float(args.Residue_Weight_Sheet)
else:
	dssp_E_weight = 0.0

if args.Residue_Weight_Loop:
	dssp_L_weight = 1.0 - float(args.Residue_Weight_Loop)
else:
	dssp_L_weight = 0.5

if args.Residue_Weight_Helix:
	dssp_H_weight = 1.0 - float(args.Residue_Weight_Helix)
else:
	dssp_H_weight = 0.5

sec_struct_weight = {'L':float(dssp_L_weight), 'H':float(dssp_H_weight), 'E':float(dssp_E_weight)}

### Preparing Unweighted Score Functions
sf_env = ScoreFunction()
sf_env.set_weight(env, 1.0)

sf_pair = ScoreFunction()
sf_pair.set_weight(pair, 1.0)

sf_cbeta = ScoreFunction()
sf_cbeta.set_weight(cbeta, 1.0)

### Centroid DSSP Weighted Pair Term
@pyrosetta.EnergyMethod()
class SecondaryStructurePenalty(ContextIndependentTwoBodyEnergy):
	"""A scoring method that assigns different score weights to residues
	depending on the secondary structure.

	"""
	def __init__(self):
		"""Construct LengthScoreMethod."""
		ContextIndependentTwoBodyEnergy.__init__(self, self.creator())

	def setup_for_scoring(self, pose, sf):
		pose = pose
		dssp.apply(pose)

	def defines_intrares_energy(self, weights):
		"""Return True if intra-residue energy is Defined."""
		return True

	def eval_intrares_energy(self, res, pose, sf, emap):
		"""Calculate intra-residue energy if defined."""
		pose = pose
		emv = EMapVector()
		sf_env.eval_cd_1b(res,pose,emv)
		weighted_score_env = emv[env]*sec_struct_weight[pose.secstruct()[res.seqpos()-1]]
		sf_cbeta.eval_cd_1b(res,pose,emv)
		weighted_score_cbeta = emv[cbeta]*sec_struct_weight[pose.secstruct()[res.seqpos()-1]]
		weighted_score = -1*(weighted_score_env + weighted_score_cbeta)
		emap.set(self.scoreType, weighted_score)


	def atomic_interaction_cutoff(self):
		"""Get the cutoff."""
		return 0.0

	def residue_pair_energy(self, res1, res2, pose, sf, emap):
		"""Calculate energy of res of pose and set emap"""
		pose = pose
		emv = EMapVector()
		sf_pair.eval_ci_2b(res1,res2,pose,emv)
		weighted_score = -1*(emv[pair]*sec_struct_weight[pose.secstruct()[res1.seqpos()-1]]*sec_struct_weight[pose.secstruct()[res2.seqpos()-1]])
		emap.set(self.scoreType, weighted_score)

secstrucpenalty_score = SecondaryStructurePenalty.scoreType

## Preparing Score Functions
if args.Rg_Weight:
	rg_reweight_factor = args.Rg_Weight
else:
	rg_reweight_factor = 0.5

sf0 = create_score_function('score0')
sf_stage_1 = create_score_function('score0')

sf_stage_2 = create_score_function('score1')
sf_stage_2.set_weight(secstrucpenalty_score, 1.0)

sf_stage_3a = create_score_function('score2')
sf_stage_3a.set_weight(secstrucpenalty_score, 1.0)

sf_stage_3b = create_score_function('score5')
sf_stage_3b.set_weight(secstrucpenalty_score, 1.0)

sf_stage_4 = create_score_function('score3')
if args.AbInitioVO == True:
	sf_stage_4.set_weight(rg, 0.0)
	sf_stage_4.set_weight(new_rg_score, ((400/24)*5))
else:
	sf_stage_4.set_weight(rg, sf_stage_4.get_weight(rg)*rg_reweight_factor)
sf_stage_4.set_weight(hbond_sr_bb, 1.0)
sf_stage_4.set_weight(hbond_lr_bb, 1.0)
sf_stage_4.set_weight(rama, 1.0)
sf_stage_4.set_weight(secstrucpenalty_score, 1.0)

## Setting Up Stage 4
sf_stage_4_term_list = [vdw, hbond_sr_bb, hbond_lr_bb, rama, new_rg_score]
cen_score_holder_dtypes = [('out_name', np.unicode_, 100)]
for score_4_term in range(len(sf_stage_4_term_list)):
	cen_score_holder_dtypes.append((str(sf_stage_4_term_list[score_4_term]), float))
cen_score_holder = np.zeros([int(abnstruct)], dtype=cen_score_holder_dtypes)

## Full Atom Score Functions
sfbeta = create_score_function('ref2015')
sfrelax = create_score_function('ref2015_cart')

## Radius of Gyration Reference Score Function
sfrg = ScoreFunction()
sfrg.set_weight(rg, 1.0)

# The Movers
## Fragment Movers
# Importing the fragment files
fragset9 = ConstantLengthFragSet(9)
fragset9.read_fragment_file(args.Nine_Mer_Frag_Library)
fragset3 = ConstantLengthFragSet(3)
fragset3.read_fragment_file(args.Three_Mer_Frag_Library)

# Constructing the Fragment Mover
fragmover9 = ClassicFragmentMover(fragset9, maplow)
fragmover3 = ClassicFragmentMover(fragset3, maplow)
gunncost = GunnCost()
smoothfragmover3 = SmoothFragmentMover(fragset3, maplow, gunncost)

## Phi-Psi Movers
smMovercen = SmallMover(maplow, 0.8, 1)
shMovercen = ShearMover(maplow, 0.8, 1)
smMovercen.angle_max("H", 2.0)
smMovercen.angle_max("E", 2.0)
smMovercen.angle_max("L", 5.0)
shMovercen.angle_max("H", 2.0)
shMovercen.angle_max("E", 2.0)
shMovercen.angle_max("L", 5.0)

smMoverfa = SmallMover(maplow, 0.8, 1)
shMoverfa = ShearMover(maplow, 0.8, 1)
smMoverfa.angle_max("H", 2.0)
smMoverfa.angle_max("E", 2.0)
smMoverfa.angle_max("L", 5.0)
shMoverfa.angle_max("H", 2.0)
shMoverfa.angle_max("E", 2.0)
shMoverfa.angle_max("L", 5.0)

##Random Movers
random_stage_1 = RandomMover()
random_stage_1.add_mover(fragmover9)

random_stage_2 = RandomMover()
random_stage_2.add_mover(fragmover9)

random_stage_3 = RandomMover()
random_stage_3.add_mover(fragmover9)

random_stage_4a = RandomMover()
random_stage_4a.add_mover(fragmover3)

random_stage_4b = RandomMover()
random_stage_4b.add_mover(smoothfragmover3)


# Relax Mover
relax = rosetta.protocols.relax.FastRelax()
relax.min_type('lbfgs_armijo_nonmonotone')
relax.dualspace(True)
relax.set_scorefxn(sfrelax)
relax.max_iter(200)

# The Monte Carlo
## PyRosetta Monte Carlo Objects
mc_stage_1 = MonteCarlo(p, sf_stage_1, 2.0)
mc_stage_2 = MonteCarlo(p, sf_stage_2, 2.0)
mc_stage_3a = MonteCarlo(p, sf_stage_3a, 2.0)
mc_stage_3b = MonteCarlo(p, sf_stage_3b, 2.0)
mc_stage_4 = MonteCarlo(p, sf_stage_4, 2.0)

## Setting up Trial Movers
trial_stage_1 = TrialMover(random_stage_1, mc_stage_1)
trial_stage_2 = TrialMover(random_stage_2, mc_stage_2)
trial_stage_3a = TrialMover(random_stage_3, mc_stage_3a)
trial_stage_3b = TrialMover(random_stage_3, mc_stage_3b)
trial_stage_4a = TrialMover(random_stage_4a, mc_stage_4)
trial_stage_4b = TrialMover(random_stage_4b, mc_stage_4)

## Setting up Repeat Movers
stage1 = RepeatMover(trial_stage_1, 2000)
stage2 = RepeatMover(trial_stage_2, 2000)
stage3a = RepeatMover(trial_stage_3a, 4000)
stage3b = RepeatMover(trial_stage_3b, 4000)
stage4a = RepeatMover(trial_stage_4a, 4000)
stage4b = RepeatMover(trial_stage_4b, 4000)

# Converting the Pose
switch = SwitchResidueTypeSetMover('fa_standard')

# Side-Chain Movers
switch.apply(fa_p)
task = standard_packer_task(fa_p)
task.restrict_to_repacking()
pack_mover = PackRotamersMover(sfbeta, task)
rot_mover = RotamerTrialsMover(sfbeta, task)

# The Simulation and Output
for i in range(int(abnstruct)):
	# Setting up the Input Structure
	p.assign(starting_p)
	for pose_res_num in range(p.total_residue()):
		p.set_phi(pose_res_num+1,-150)
		p.set_psi(pose_res_num+1,150)
		p.set_omega(pose_res_num+1,180)
	mc_stage_1.reset(p)
	mc_stage_2.reset(p)
	mc_stage_3a.reset(p)
	mc_stage_3b.reset(p)
	mc_stage_4.reset(p)
	for j in range(cycles):
		print('Performing Stage 1 Sampling: Phase: ' + str(j))
		sf_env.set_weight(env, sf_stage_1.get_weight(env))
		sf_pair.set_weight(pair, sf_stage_1.get_weight(pair))
		sf_cbeta.set_weight(cbeta, sf_stage_1.get_weight(cbeta))
		stage1.apply(p)
		mc_stage_1.recover_low(p)
		sf_stage_1.show(p)
		mc_stage_1.reset(p)
	for k in range(cycles):
		print('Performing Stage 2 Sampling: Phase: ' + str(k))
		sf_env.set_weight(env, sf_stage_2.get_weight(env))
		sf_pair.set_weight(pair, sf_stage_2.get_weight(pair))
		sf_cbeta.set_weight(cbeta, sf_stage_2.get_weight(cbeta))
		stage2.apply(p)
		mc_stage_2.recover_low(p)
		sf_stage_2.show(p)
		mc_stage_2.reset(p)
	for l in range(int(cycles/2)):
		print('Performing Stage 3 Sampling: Phase: ' + str(l))
		if l % 2 == 0:
			sf_env.set_weight(env, sf_stage_3a.get_weight(env))
			sf_pair.set_weight(pair, sf_stage_3a.get_weight(pair))
			sf_cbeta.set_weight(cbeta, sf_stage_3a.get_weight(cbeta))
			stage3a.apply(p)
			mc_stage_3a.recover_low(p)
			mc_stage_3a.reset(p)
		else:
			sf_env.set_weight(env, sf_stage_3b.get_weight(env))
			sf_pair.set_weight(pair, sf_stage_3b.get_weight(pair))
			sf_cbeta.set_weight(cbeta, sf_stage_3b.get_weight(cbeta))
			stage3b.apply(p)
			mc_stage_3b.recover_low(p)
			mc_stage_3b.reset(p)
		sf_stage_3b.show(p)
	for m in range(cycles):
		print('Performing Stage 4 Sampling: Phase: ' + str(m))
		sf_env.set_weight(env, sf_stage_4.get_weight(env))
		sf_pair.set_weight(pair, sf_stage_4.get_weight(pair))
		sf_cbeta.set_weight(cbeta, sf_stage_4.get_weight(cbeta))
		if m < 2:
			stage4a.apply(p)
			mc_stage_4.recover_low(p)
		else:
			stage4b.apply(p)
			mc_stage_4.recover_low(p)
		sf_stage_4.show(p)
		mc_stage_4.reset(p)
	for record_idx in range(len(sf_stage_4_term_list)):
		cen_score_holder[i][record_idx] = p.energies().total_energies()[sf_stage_4_term_list[record_idx]]
	pcen.assign(p)
	if args.AbInitioVO == True:
		outf = open("AbInitioVO_Centroid.sc", 'a')
		pdb_out = "AbInitioVO_Centroid_out_%i.pdb" %i
	else:
		outf = open("AbInitio_Centroid.sc", 'a')
		pdb_out = "AbInitio_Centroid_out_%i.pdb" %i
	pcen.dump_pdb(pdb_out)
	switch.apply(p)
	sfbeta.show(p)
	outf.write("%s\t%.3f\t%.4f\t%.3f\n" % (pdb_out, sfbeta(p), sf_stage_4(pcen), sfrg(p)))
	outf.close()
np.savetxt('Centroid_Score_Breakdown.txt', cen_score_holder, fmt='%s', delimiter=' ', newline='\n')

## Deciding who to minimize
dtype_list = [('out_name','S50'),('full_sc',float),('cen_score',float),('out_rg',float)]
if args.AbInitioVO == True:
	cen_out_data = np.genfromtxt('AbInitioVO_Centroid.sc', dtype=dtype_list)
else:
	cen_out_data = np.genfromtxt('AbInitio_Centroid.sc', dtype=dtype_list)
cen_out_sort = np.sort(cen_out_data, order='cen_score')
for cen_out_struct_idx in range(refine_number):
	cen_out_struct_item = cen_out_data[cen_out_struct_idx]['out_name']
	relax_p_in = pose_from_pdb(str(cen_out_struct_item.decode('UTF-8')))
	relax_p = Pose()
	print('Relaxing Output ' + str(cen_out_struct_idx+1) + ' of ' + str(refine_number))
	for relnstruct_idx in range(relnstruct):
		relax_p.assign(relax_p_in)
		relax.apply(relax_p)
		sfrelax.show(relax_p)
		if args.AbInitioVO == True:
			outf = open("AbInitioVO_FullAtom.sc", 'a')
			pdb_out = "AbInitioVO_FullAtom_out_" + str(cen_out_struct_idx) + "_" + str(relnstruct_idx) + ".pdb"
		else:
			outf = open("AbInitio_FullAtom.sc", 'a')
			pdb_out = "AbInitio_FullAtom_out_" + str(cen_out_struct_idx) + "_" + str(relnstruct_idx) + ".pdb"
		outf.write("%s\t%s\t%.4f\t%.4f\n" % (pdb_out, str(cen_out_struct_item), sfrelax(relax_p), sfrg(relax_p)))
		sfrelax(relax_p)
		relax_p.dump_pdb(pdb_out)
		outf.close()
